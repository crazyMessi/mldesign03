[TOC]

## 注意事项

**网络层可视化**

目前已经有很多网络层可视化的工具了 大伙可以都试试看

[简易版教程](https://zhuanlan.zhihu.com/p/220403674)

[或者使用tensorboard](https://zhuanlan.zhihu.com/p/58961505)



**数据集合**

>描述一下数据集概况
>
>或许可以尝试缩小数据集



**代码注释**

读代码的时候注意多写注释 尤其是关键函数和一些比较难理解的函数



**调参/网络层**

不同参数结果对比 注意每次对比时需要有逻辑,比如为什么要改这些参数,改完以后可以印证什么or得出什么结论

除了调参 还可以尝试调整关键网络层

比如验证dropout



**结果分析**

<font color='red'>重点回答任务书里面的几个问题</font>

* 分析并列出影响各个模型实验结果的<font color='red'>主要原因</font>
* 列出不同算法的优劣
  * FLOPs与时间复杂度
  * 对超参的敏感程度
  * 对数据量的需求



## AutoEncoder

### 模型架构

>* 网络层设计
>* loss计算
>* 相比之前的模型有什么改进

### 原理分析

>查相关资料

### 运行结果

>* 训练情况
>  * loss下降情况
>
>* 测试集表现



## GAN

### 模型架构

>尝试可视化一下整体架构(这里不是指网络层 而是两个模型相互的关系)

**AutoEncoder**

>基于AutoEncoder 但loss函数不一样 (为什么要这么改)

**Discriminator**

>loss计算
>
>是怎么想到loss的

### 原理分析

> 为什么有用(尝试从理论的角度)

### 运行结果

>对比AutoEncoder



## Pix2pix

### 模型架构

>skip connection是怎么做的

### 原理分析

>为什么要skip connection

### 运行结果





### 尝试

* 对结果进行适当的低级图像处理，比如一些滤波操作
* 把图片通道数量改成1。因为我们**主要关注字体变形，不关注颜色**。
* 在原有模型上再加一个unet（和原来模型不一起训练），因为目前的pix2pix形状已经比较形似了，可以尝试单独训练一个unet让成像更清晰的模型。即**一个模型学习形态的变化，另一个模型对结果进行降噪处理**
* 修改网络层的设置。
  * 当前的训练loss似乎还有降低的空间，或许可以让网络层更深一点? 
  * **在网络尾部增加一个softmax**。因为我们看了一下经过生成器前后的图片的灰度直方图，发现映射后的图片的直方图多了很多”杂灰度“，即多了一些半黑不白的地方，而这类灰度是原图片以及目标图片所没有的
* 我们查阅了一下相关资料，很多人说Unet的skip connection的作用主要是在上采样时还原图片的一些空间特征。据了解，resnet中也有一个skip connection，用于缓解网络过深导致的优化困难。这两个skip connection之间存在联系吗？我们的Unet有12层，**是否也需要引进残差学习**?
* 使用cycleGAN











