{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64169270",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:09.944959Z",
     "iopub.status.busy": "2022-03-07T06:00:09.944085Z",
     "iopub.status.idle": "2022-03-07T06:00:31.510439Z",
     "shell.execute_reply": "2022-03-07T06:00:31.509594Z",
     "shell.execute_reply.started": "2022-03-07T03:36:05.521633Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 21.591932,
     "end_time": "2022-03-07T06:00:31.510596",
     "exception": false,
     "start_time": "2022-03-07T06:00:09.918664",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: progressbar2 in /opt/conda/lib/python3.7/site-packages (4.0.0)\r\n",
      "Requirement already satisfied: python-utils>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from progressbar2) (3.1.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Collecting fitlog\r\n",
      "  Downloading fitlog-0.9.13.tar.gz (925 kB)\r\n",
      "     |████████████████████████████████| 925 kB 596 kB/s            \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.7/site-packages (from fitlog) (0.6.2)\r\n",
      "Requirement already satisfied: flask>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from fitlog) (2.0.3)\r\n",
      "Requirement already satisfied: numpy>=1.16.4 in /opt/conda/lib/python3.7/site-packages (from fitlog) (1.20.3)\r\n",
      "Requirement already satisfied: gitpython>=3.1.2 in /opt/conda/lib/python3.7/site-packages (from fitlog) (3.1.24)\r\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from flask>=1.0.2->fitlog) (2.0.2)\r\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from flask>=1.0.2->fitlog) (8.0.3)\r\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from flask>=1.0.2->fitlog) (3.0.3)\r\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from flask>=1.0.2->fitlog) (2.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from gitpython>=3.1.2->fitlog) (4.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=3.1.2->fitlog) (4.0.9)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1.2->flask>=1.0.2->fitlog) (4.11.2)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->fitlog) (3.0.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->flask>=1.0.2->fitlog) (2.1.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->flask>=1.0.2->fitlog) (3.6.0)\r\n",
      "Building wheels for collected packages: fitlog\r\n",
      "  Building wheel for fitlog (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fitlog: filename=fitlog-0.9.13-py3-none-any.whl size=967495 sha256=bd783b2d84cf2837c7aab050c2555c5f7912f9d55d79c34b0cc5626ea2190925\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7d/95/d4/a1a752c27fad922c452674b431fb58417ac6de1a530c8a6d05\r\n",
      "Successfully built fitlog\r\n",
      "Installing collected packages: fitlog\r\n",
      "Successfully installed fitlog-0.9.13\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "\u001b[34mAuto commit by fitlog\u001b[0m\r\n",
      "\u001b[32mFitlog project . is initialized.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2\n",
    "!pip install fitlog\n",
    "!fitlog init\n",
    "%mkdir utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26b66ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.556052Z",
     "iopub.status.busy": "2022-03-07T06:00:31.555312Z",
     "iopub.status.idle": "2022-03-07T06:00:31.558425Z",
     "shell.execute_reply": "2022-03-07T06:00:31.559009Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.841635Z"
    },
    "papermill": {
     "duration": 0.027847,
     "end_time": "2022-03-07T06:00:31.559176",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.531329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing command.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile command.py\n",
    "import os\n",
    "\n",
    "ep = 400\n",
    "lrG = 0.0001\n",
    "bs = 16\n",
    "\n",
    "os.system('python my_train.py --model_name AutoEncoderGen --ep %d --lrG %f --bs %d' % (ep, lrG, bs))\n",
    "os.system('python my_train.py --model_name GAN --ep %d --lrG %f --bs %d' % (ep, lrG, bs))\n",
    "os.system('python my_train.py --model_name pic2pic --ep %d --lrG %f --bs %d' % (ep, lrG, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6bad9d6",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.606894Z",
     "iopub.status.busy": "2022-03-07T06:00:31.606151Z",
     "iopub.status.idle": "2022-03-07T06:00:31.609359Z",
     "shell.execute_reply": "2022-03-07T06:00:31.609903Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.849880Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030727,
     "end_time": "2022-03-07T06:00:31.610065",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.579338",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_train.py\n",
    "import argparse\n",
    "import fitlog\n",
    "import io\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import *\n",
    "import utils.file_manager as fm\n",
    "\n",
    "from utils.model_controller import *\n",
    "\n",
    "try:\n",
    "    import ipdb\n",
    "except:\n",
    "    import pdb as ipdb\n",
    "\n",
    "import time\n",
    "import progressbar\n",
    "\n",
    "pro = progressbar.ProgressBar()\n",
    "\n",
    "parser = argparse.ArgumentParser()  # 创建解析器对象 可以添加参数\n",
    "parser.add_argument('--model_name', type=str, default='test', help='模型名称')\n",
    "parser.add_argument('--lrG', type=float, default=1e-4, help='adam: learning rate')\n",
    "parser.add_argument('--lrD', type=float, default=1e-4, help='adam: learning rate')\n",
    "parser.add_argument('--bs', type=int, default=8, help='size of the batches')\n",
    "parser.add_argument('--ep', type=int, default=200, help='number of epochs of training')\n",
    "parser.add_argument('--lrG_d', type=int, default=90, help='G lr down')\n",
    "parser.add_argument('--lrD_d', type=int, default=10, help='D lr down')\n",
    "parser.add_argument('--weight_pic', type=float, default=10, help='计算生成器loss时,pic_loss的比例')\n",
    "parser.add_argument('--epoch', type=int, default=0, help='epoch to start training from')\n",
    "parser.add_argument('--dataset_name', type=str, default='test', help='name of the dataset')\n",
    "\n",
    "parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\n",
    "parser.add_argument('--decay_epoch', type=int, default=100, help='epoch from which to start lr decay')\n",
    "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
    "parser.add_argument('--img_height', type=int, default=64, help='size of image height')\n",
    "parser.add_argument('--img_width', type=int, default=64, help='size of image width')\n",
    "parser.add_argument('--channels', type=int, default=3, help='number of image channels')\n",
    "parser.add_argument('--sample_interval', type=int, default=500,\n",
    "                    help='interval between sampling of images from generators')\n",
    "parser.add_argument('--checkpoint_interval', type=int, default=20, help='interval between model checkpoints')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "if_fitlog = True\n",
    "\n",
    "data_path = '../input/mldesign03/fontdata'\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "test = True\n",
    "\n",
    "train_opt = fm.Train_opt(opt)\n",
    "# Initialize generator and discriminator\n",
    "model_name = train_opt['model_name']\n",
    "\n",
    "if if_fitlog:\n",
    "    fitlog.set_log_dir('logs/')  # 设置log文件夹为'logs/', fitlog在每次运行的时候会默认以时间戳的方式在里面生成新的log\n",
    "    fitlog.add_hyper(train_opt.get_fitlog_hyper())\n",
    "\n",
    "transforms_ = [transforms.ToTensor(),\n",
    "               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "# 修改成本地存放数据集地址\n",
    "dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_),\n",
    "                        batch_size=opt.bs, shuffle=True, num_workers=0)\n",
    "train_opt['dataloader_length'] = len(dataloader)\n",
    "\n",
    "val_dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_, mode='train'),\n",
    "                            batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "# Tensor type\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "\n",
    "model = model_selector(train_opt.opt)\n",
    "# 为网络参数赋初值\n",
    "model.apply(weights_init_normal)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    imgs = next(iter(val_dataloader))\n",
    "    real_A = imgs['B'].type(Tensor)\n",
    "    real_B = imgs['A'].type(Tensor)\n",
    "    fake_B = model.generator(real_A)\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n",
    "    # ipdb.set_trace()\n",
    "    save_image(img_sample, train_opt.get_img_root() + '%s.png' % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "model.train()\n",
    "\n",
    "min_tloss = 500\n",
    "tloss_res = {}\n",
    "\n",
    "bs_count = len(dataloader)\n",
    "pro.start(train_opt['ep'] * bs_count)\n",
    "\n",
    "for epoch in range(opt.epoch, opt.ep):\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Model inputs\n",
    "        source = batch['B'].type(Tensor)\n",
    "        target = batch['A'].type(Tensor)\n",
    "        loss_dic = model.step(source, target)\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        # If at sample interval save image\n",
    "        if int(batches_done*train_opt['bs']/8) % int(train_opt['sample_interval']) == 0:\n",
    "            sample_images(batches_done)\n",
    "        # 打印进度条\n",
    "        pro.update(i + epoch * bs_count)\n",
    "\n",
    "    avg_loss = 0\n",
    "    tloss_res[epoch] = avg_loss\n",
    "\n",
    "    if if_fitlog:\n",
    "        fitlog.add_metric(loss_dic, epoch)\n",
    "        fitlog.add_best_metric(loss_dic)\n",
    "\n",
    "    # 每50轮保存模型参数\n",
    "    if epoch > 0 and (epoch + 1) % 50 == 0:\n",
    "        torch.save(model.state_dict(), '%s/%s_%d.pth' % (train_opt.get_model_root(), model_name, epoch))\n",
    "        # torch.save(discriminator.state_dict(),\n",
    "        #            train_opt.get_model_root() + '/discriminator_%d.pth' % epoch)\n",
    "        # torch.save(model.state_dict())\n",
    "    # 保存loss最小时的模型参数\n",
    "    # if tloss_res[epoch] < min_tloss:\n",
    "    #     min_tloss = tloss_res[epoch]\n",
    "    #     tloss_res['min'] = tloss_res[epoch]\n",
    "    #     tloss_res['minepoch'] = epoch\n",
    "    #     torch.save(model.state_dict(), '%s/%s_min.pth' % (train_opt.get_model_root(), model_name))\n",
    "\n",
    "with io.open(train_opt.get_log_root() + 'list_loss.txt', 'a', encoding='utf-8') as file:\n",
    "    file.write('tloss_res: {} \\n'.format(tloss_res))\n",
    "pro.finish()\n",
    "if test:\n",
    "    os.system('python test.py --model_dir \\\"%s\\\" --model_name %s' % (train_opt.get_model_root(), model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6746e18",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.655323Z",
     "iopub.status.busy": "2022-03-07T06:00:31.654526Z",
     "iopub.status.idle": "2022-03-07T06:00:31.657947Z",
     "shell.execute_reply": "2022-03-07T06:00:31.658471Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.865540Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028205,
     "end_time": "2022-03-07T06:00:31.658629",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.630424",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "import argparse\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from utils.file_manager import *\n",
    "from dataset import *\n",
    "import torch\n",
    "\n",
    "from utils.model_controller import model_selector\n",
    "\n",
    "try:\n",
    "    import ipdb\n",
    "except:\n",
    "    import pdb as ipdb\n",
    "\n",
    "parser = argparse.ArgumentParser()  # 创建解析器对象 可以添加参数\n",
    "# 为了找到训练模型参数地址，要与train.py中model_name参数一致\n",
    "parser.add_argument('--model_dir', type=str, default=\"test\", help='模型文件夹')\n",
    "parser.add_argument('--model_name', type=str, default=\"test\", help='模型名')\n",
    "opt = parser.parse_args()\n",
    "my_opt = Test_opt(opt)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "data_path = '../input/mldesign03/fontdata'\n",
    "model = model_selector(my_opt.opt['model_name'])\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "transforms_ = [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "# ImageDataset第一个参数改成个人数据集存放地址\n",
    "val_dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_, mode='test'),\n",
    "                            batch_size=20, shuffle=False, num_workers=0)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "model_dict = my_opt.get_model_root()\n",
    "filename = os.listdir(model_dict)\n",
    "\n",
    "for j in range(len(filename)):\n",
    "    if os.path.splitext(filename[j])[1] == '.pth':\n",
    "        model.load_state_dict(torch.load('%s/%s' % (model_dict, filename[j])))\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(val_dataloader):\n",
    "            print(i)\n",
    "            real_A = Variable(batch['B'].type(Tensor))\n",
    "            real_B = Variable(batch['A'].type(Tensor))\n",
    "            fake_B = model.generator(real_A)\n",
    "            # 图片存放处\n",
    "            save_image(fake_B, my_opt.get_img_root()+'/%s.png' % ('img'+str(i) + '_' + filename[j].split('.')[0]), nrow=10,\n",
    "                       normalize=True)\n",
    "            save_image(real_B, my_opt.get_img_root()+'/%s.png' % str(i), nrow=10, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c7180d",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.710414Z",
     "iopub.status.busy": "2022-03-07T06:00:31.709527Z",
     "iopub.status.idle": "2022-03-07T06:00:31.713612Z",
     "shell.execute_reply": "2022-03-07T06:00:31.712973Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.878812Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034392,
     "end_time": "2022-03-07T06:00:31.713745",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.679353",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing myModel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile myModel.py\n",
    "from torch import nn\n",
    "from utils.my_optimizer import *\n",
    "\n",
    "generator_loss_fun = torch.nn.L1Loss()\n",
    "discriminator_loss_fun = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "# ===================================\n",
    "#              网络单元\n",
    "# ===================================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0, ks=4):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, kernel_size=ks, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.0, normalize=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        layers = [nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0, ks=4):\n",
    "\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, kernel_size=ks, stride=2, padding=1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_size, out_size, dropout=0.0, if_crop=True):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "                  nn.InstanceNorm2d(out_size),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.if_crop = if_crop\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        # ipdb.set_trace()\n",
    "        x = self.model(x)\n",
    "        if self.if_crop > 0:\n",
    "            x = torch.cat((x, skip_input), 1)\n",
    "        else:\n",
    "            x = torch.cat((x, x), 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ===================================\n",
    "#              子模型\n",
    "# ===================================\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, if_crop=True, loss_fun=generator_loss_fun):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.5)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.5)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.5, normalize=False)  # 不需要正规化了\n",
    "\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5, if_crop=if_crop)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5, if_crop=if_crop)\n",
    "        self.up3 = UNetUp(1024, 256, if_crop=if_crop)\n",
    "        self.up4 = UNetUp(512, 128, if_crop=if_crop)\n",
    "        self.up5 = UNetUp(256, 64, if_crop=if_crop)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.loss_fun = loss_fun\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        d1 = self.down1(x)  # x:[1, 3, 64, 64]  d1:[1, 64, 32, 32]\n",
    "        d2 = self.down2(d1)  # d2:[1,128,16,16]\n",
    "        d3 = self.down3(d2)  # d3:[1,256,8,8]\n",
    "        d4 = self.down4(d3)  # d4:[1,512,4,4]\n",
    "        d5 = self.down5(d4)  # d5:[1,512,2,2]\n",
    "        d6 = self.down6(d5)  # d6:[1,512,1,1]\n",
    "\n",
    "        u1 = self.up1(d6, d5)  # u1:[1,1024,2,2]\n",
    "        u2 = self.up2(u1, d4)  # u2:[1,1024,4,4]\n",
    "        u3 = self.up3(u2, d3)  # u3:[1,1024,8,8]\n",
    "        u4 = self.up4(u3, d2)  # u4:[1,1024,16,16]\n",
    "        u5 = self.up5(u4, d1)  # u5:[1,512,32,32]\n",
    "        return self.final(u5)\n",
    "\n",
    "    def loss(self, generate, target):\n",
    "        return self.loss_fun(generate, target)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, loss_fun=discriminator_loss_fun):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "        self.loss_fun = loss_fun\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        # Concatenate image and condition image\n",
    "        # by channels to produce input\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "    def loss(self, pred, real):\n",
    "        return self.loss_fun(pred, real)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, loss_fun=generator_loss_fun):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.down1 = Encoder(in_channels, 64, normalize=False)\n",
    "        self.down2 = Encoder(64, 128)\n",
    "        self.down3 = Encoder(128, 256)\n",
    "        self.down4 = Encoder(256, 512, dropout=0.5)\n",
    "        self.down5 = Encoder(512, 512, dropout=0.5)\n",
    "        self.down6 = Encoder(512, 512, dropout=0.5, normalize=False)  # 不需要正规化了\n",
    "\n",
    "        self.up1 = Decoder(512, 1024, dropout=0.5)\n",
    "        self.up2 = Decoder(1024, 1024, dropout=0.5)\n",
    "        self.up3 = Decoder(1024, 512)\n",
    "        self.up4 = Decoder(512, 256)\n",
    "        self.up5 = Decoder(256, 128)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.loss_fun = loss_fun\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 上采样\n",
    "        d1 = self.down1(x)  # x:[1, 3, 64, 64]  d1:[1, 64, 32, 32]\n",
    "        d2 = self.down2(d1)  # d2:[1,128,16,16]\n",
    "        d3 = self.down3(d2)  # d3:[1,256,8,8]\n",
    "        d4 = self.down4(d3)  # d4:[1,512,4,4]\n",
    "        d5 = self.down5(d4)  # d5:[1,512,2,2]\n",
    "        d6 = self.down6(d5)  # d6:[1,512,1,1]\n",
    "        # 下采样\n",
    "        u1 = self.up1(d6)  # u1:[1,1024,2,2]\n",
    "        u2 = self.up2(u1)  # u2:[1,1024,4,2]\n",
    "        u3 = self.up3(u2)  # u3:[1,1024,8,2]\n",
    "        u4 = self.up4(u3)  # u4:[1,1024,16,16]\n",
    "        u5 = self.up5(u4)  # u5:[1,512,32,32]\n",
    "        x = self.final(u5)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        return self.loss_fun(x, y)\n",
    "\n",
    "\n",
    "# ===================================\n",
    "#              顶级模型\n",
    "# ===================================\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, train_opt=None, generator=GeneratorUNet(), discriminator=Discriminator()):\n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        if isinstance(train_opt, dict):\n",
    "            self.optimizer_G = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrG'],\n",
    "                                              betas=(train_opt['b1'], train_opt['b2']),\n",
    "                                              freq=train_opt['lrG_d'] * train_opt['dataloader_length'])\n",
    "\n",
    "            self.optimizer_D = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrD'],\n",
    "                                              betas=(train_opt['b1'], train_opt['b2']),\n",
    "                                              freq=train_opt['lrD_d'] * train_opt['dataloader_length'])\n",
    "            self.train_opt = train_opt\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        generate = self.generator(source)\n",
    "        source_generate = self.discriminator(generate, source)\n",
    "        source_target = self.discriminator(target, source)\n",
    "        source_generate2 = self.discriminator(generate.detach(), source)\n",
    "        return generate, source_generate, source_target, source_generate2\n",
    "\n",
    "    def loss(self, generate, target, source_generate, source_target, source_generate2):\n",
    "        invalid = source_target.clone().detach() * 0\n",
    "        valid = invalid + 1\n",
    "        # 计算生成模型误差\n",
    "        loss_pixel = self.generator.loss(generate, target)\n",
    "        loss_sVg = self.discriminator.loss(source_generate, valid)\n",
    "        loss_G = loss_sVg + self.train_opt['weight_pic'] * loss_pixel\n",
    "        # 分辨源图像和目标图像\n",
    "        loss_real = self.discriminator.loss(source_target, valid)\n",
    "        # 分辨源图像和生成图像\n",
    "        loss_fake = self.discriminator.loss(source_generate2, invalid)\n",
    "        # Total loss\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        return loss_G, loss_D, loss_sVg, loss_pixel\n",
    "\n",
    "    def step(self, source, target):\n",
    "        generate, source_generate, source_target, source_generate2 = self(source, target)\n",
    "        loss_G, loss_D, loss_sVg, loss_pixel = self.loss(generate, target, source_generate,\n",
    "                                                         source_target, source_generate2)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        self.optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        self.optimizer_D.step()\n",
    "        loss_dic = {'loss_G': loss_G.item(), 'loss_D': loss_D.item(), 'loss_pixel': loss_pixel.item(),\n",
    "                    'loss_sVg': loss_sVg.item()}\n",
    "        return loss_dic\n",
    "\n",
    "\n",
    "# 基于AutoEncoder的图片生成器\n",
    "class AutoEncoderGen(nn.Module):\n",
    "    def __init__(self, train_opt=None, generator=AutoEncoder()):\n",
    "        super(AutoEncoderGen, self).__init__()\n",
    "        self.generator = generator\n",
    "        if isinstance(train_opt, dict):\n",
    "            self.optimizer_G = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrG'],\n",
    "                                              betas=(train_opt['b1'], train_opt['b2']),\n",
    "                                              freq=train_opt['lrG_d'] * train_opt['dataloader_length'])\n",
    "\n",
    "    def loss(self, x, y):\n",
    "        return self.generator.loss_fun(x, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    # 只有作为顶级模型时该方法有效合法\n",
    "    def step(self, x, y):\n",
    "        generate = self(x)\n",
    "        loss_pixel = self.loss(y, generate) * 10\n",
    "        self.optimizer_G.zero_grad()\n",
    "        loss_pixel.backward()\n",
    "        self.optimizer_G.step()\n",
    "        loss_dic = {'loss_pixel': loss_pixel.item()}\n",
    "        return loss_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e958b04",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.759489Z",
     "iopub.status.busy": "2022-03-07T06:00:31.758841Z",
     "iopub.status.idle": "2022-03-07T06:00:31.761788Z",
     "shell.execute_reply": "2022-03-07T06:00:31.762478Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.895789Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027904,
     "end_time": "2022-03-07T06:00:31.762631",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.734727",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "try:\n",
    "    import ipdb\n",
    "except:\n",
    "    import pdb as ipdb\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_=None, mode='train'):\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        # ipdb.set_trace()\n",
    "        rootPath = root + '/{}'.format(mode)\n",
    "        filename = os.listdir(rootPath)\n",
    "        path = rootPath + '/' + filename[0]\n",
    "\n",
    "        self.imgs = np.load(path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_A_a = self.imgs[index][:, :64, :]\n",
    "        img_B_b = self.imgs[index][:, 64:, :]\n",
    "\n",
    "        img_A = self.transform(img_A_a.astype(np.uint8))  # 京黑\n",
    "        img_B = self.transform(img_B_b.astype(np.uint8))  # 黑体\n",
    "\n",
    "        return {'A': img_A, 'B': img_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2f36b8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.811093Z",
     "iopub.status.busy": "2022-03-07T06:00:31.810240Z",
     "iopub.status.idle": "2022-03-07T06:00:31.813850Z",
     "shell.execute_reply": "2022-03-07T06:00:31.814382Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.907735Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030491,
     "end_time": "2022-03-07T06:00:31.814537",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.784046",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils/file_manager.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/file_manager.py\n",
    "'''\n",
    "由opt决定的文件树\n",
    "'''\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from utils.model_controller import valid_model_name\n",
    "\n",
    "\n",
    "class Train_opt:\n",
    "    def __init__(self, opt, root=os.getcwd() + '/output'):\n",
    "        super(Train_opt, self).__init__()\n",
    "        # 将opt转为字典类型\n",
    "        if not isinstance(opt, dict):\n",
    "            self.opt = vars(opt)\n",
    "        else:\n",
    "            self.opt = opt\n",
    "        self.root = root\n",
    "        self.mk_use_dirs()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.opt.__getitem__(item)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.opt.__setitem__(key, value)\n",
    "\n",
    "    # 获得本次输出的根目录\n",
    "    def get_root(self):\n",
    "        # 格式：模型/G学习率_D学习率_批大小_epoch\n",
    "        opt = self.opt\n",
    "        dir_name = ''\n",
    "        k_hyper = self.get_key_hyper()\n",
    "        for k, v in k_hyper.items():\n",
    "            dir_name += str(k) + str(v)\n",
    "        root = '%s/%s/%s/train' % (self.root, opt['model_name'], dir_name)\n",
    "        return root\n",
    "\n",
    "    # 获得log存放路径\n",
    "    def get_log_root(self):\n",
    "        return self.get_root() + '/log/'\n",
    "\n",
    "    # 获得model存放路径\n",
    "    def get_model_root(self):\n",
    "        return self.get_root() + '/model/'\n",
    "\n",
    "    # 获得img存放路径\n",
    "    def get_img_root(self):\n",
    "        return self.get_root() + '/img/'\n",
    "\n",
    "    # 返回用于命名文件夹的超参\n",
    "    def get_key_hyper(self):\n",
    "        k = ['lrG', 'lrD', 'bs', 'ep']\n",
    "        v = {key: value for key, value in self.opt.items() if key in k}\n",
    "        return v\n",
    "\n",
    "    def get_fitlog_hyper(self):\n",
    "        k = ['lrG', 'lrD', 'bs', 'ep', 'model_name']\n",
    "        v = {key: value for key, value in self.opt.items() if key in k}\n",
    "        return v\n",
    "\n",
    "    # 命名可能需要的文件夹\n",
    "    def mk_use_dirs(self):\n",
    "        print('创建 ' + self.get_img_root())\n",
    "        print('创建 ' + self.get_log_root())\n",
    "        print('创建 ' + self.get_model_root())\n",
    "        os.makedirs(self.get_log_root(), exist_ok=True)\n",
    "        os.makedirs(self.get_img_root(), exist_ok=True)\n",
    "        os.makedirs(self.get_model_root(), exist_ok=True)\n",
    "\n",
    "\n",
    "class Test_opt:\n",
    "    def __init__(self, opt):\n",
    "        super(Test_opt, self).__init__()\n",
    "        # 将opt转为字典类型\n",
    "        if not isinstance(opt, dict):\n",
    "            self.opt = vars(opt)\n",
    "        else:\n",
    "            self.opt = opt\n",
    "\n",
    "        try:\n",
    "            model_dir = self.opt['model_dir']\n",
    "            had_set = model_dir.split('/')[-4] not in valid_model_name\n",
    "        except (KeyError, IndexError):\n",
    "            print(\"未指定合法目录,请手动选择待测试模型位置\")\n",
    "            had_set = False\n",
    "\n",
    "        while self.opt['model_name'] not in valid_model_name or not had_set:\n",
    "            root = tk.Tk()\n",
    "            root.withdraw()\n",
    "            model_dir = filedialog.askdirectory()\n",
    "            self.opt['model_name'] = model_dir.split('/')[-4]\n",
    "            had_set = True\n",
    "\n",
    "        self.mode_dir = model_dir\n",
    "        self.test_out = model_dir.replace('train', 'test', 1)\n",
    "        self.test_out = self.test_out.replace('/model', '')\n",
    "        self.mk_use_dirs()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.opt.__getitem__(item)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        self.opt.__setitem__(key, value)\n",
    "\n",
    "    def get_root(self):\n",
    "        return self.test_out\n",
    "\n",
    "    def get_img_root(self):\n",
    "        return self.get_root() + '/test_img'\n",
    "\n",
    "    def get_log_root(self):\n",
    "        return self.get_root() + '/test_log'\n",
    "\n",
    "    def get_model_root(self):\n",
    "        return self.mode_dir\n",
    "\n",
    "    def mk_use_dirs(self):\n",
    "        print('创建 '+self.get_img_root())\n",
    "        print('创建 '+self.get_log_root())\n",
    "        os.makedirs(self.get_log_root(), exist_ok=True)\n",
    "        os.makedirs(self.get_img_root(), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad56ffe",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.862450Z",
     "iopub.status.busy": "2022-03-07T06:00:31.861678Z",
     "iopub.status.idle": "2022-03-07T06:00:31.865032Z",
     "shell.execute_reply": "2022-03-07T06:00:31.865598Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.921640Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029541,
     "end_time": "2022-03-07T06:00:31.865750",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.836209",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils/model_controller.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/model_controller.py\n",
    "import myModel\n",
    "from myModel import *\n",
    "\n",
    "valid_model_name = ['GAN', 'AutoEncoderGen', 'pic2pic']\n",
    "\n",
    "\n",
    "# 为网络参数赋正态分布的初值\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# 根据opt选取模型\n",
    "def model_selector(opt):\n",
    "    if isinstance(opt, dict):\n",
    "        model_name = opt['model_name']\n",
    "    else:\n",
    "        model_name = opt\n",
    "\n",
    "    generator_list = {'UNet': GeneratorUNet(), 'GAN': GeneratorUNet(if_crop=False), 'AutoEncoder': AutoEncoder()}\n",
    "    discriminator_list = {'Discriminator': Discriminator()}\n",
    "\n",
    "    while model_name not in valid_model_name:\n",
    "        print('未输入正确模型名 请输入正确模型名\\n')\n",
    "        print(valid_model_name)\n",
    "        model_name = input()\n",
    "\n",
    "    if model_name == 'AutoEncoderGen':\n",
    "        model = AutoEncoderGen(train_opt=opt, generator=generator_list['AutoEncoder'])\n",
    "\n",
    "    if model_name == 'GAN':\n",
    "        generator = generator_list['GAN']\n",
    "        discriminator = discriminator_list['Discriminator']\n",
    "        model = GAN(train_opt=opt, generator=generator, discriminator=discriminator)\n",
    "\n",
    "    if model_name == 'pic2pic':\n",
    "        generator = generator_list['UNet']\n",
    "        discriminator = discriminator_list['Discriminator']\n",
    "        model = GAN(train_opt=opt, generator=generator, discriminator=discriminator)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e5021f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.915029Z",
     "iopub.status.busy": "2022-03-07T06:00:31.914272Z",
     "iopub.status.idle": "2022-03-07T06:00:31.917731Z",
     "shell.execute_reply": "2022-03-07T06:00:31.917314Z",
     "shell.execute_reply.started": "2022-03-07T03:36:22.934601Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028528,
     "end_time": "2022-03-07T06:00:31.917867",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.889339",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils/my_optimizer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils/my_optimizer.py\n",
    "import torch\n",
    "\n",
    "\n",
    "class Adam_Optimizer:\n",
    "    # freq表示学习率折半的频率 每更新freq次参数学习率折半 (对于lrd, freq=lrG_d*dataloader_length) 当freq取0时, 不更新\n",
    "    def __init__(self, parameters, lr, betas, freq=0):\n",
    "        super(Adam_Optimizer, self).__init__()\n",
    "        self.optimizer = torch.optim.Adam(parameters, lr=lr, betas=betas)\n",
    "        self.freq = freq\n",
    "        self.times = 0\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        if self.times % self.freq == 0 and self.times > 0:\n",
    "            self.lr *= 0.5\n",
    "            self.optimizer.param_groups[0]['lr'] = self.lr\n",
    "            print(self.lr)\n",
    "        self.optimizer.step()\n",
    "        self.times += 1\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d078e37f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-07T06:00:31.965411Z",
     "iopub.status.busy": "2022-03-07T06:00:31.964700Z",
     "iopub.status.idle": "2022-03-07T06:28:54.506061Z",
     "shell.execute_reply": "2022-03-07T06:28:54.505152Z"
    },
    "papermill": {
     "duration": 1702.566701,
     "end_time": "2022-03-07T06:28:54.506212",
     "exception": false,
     "start_time": "2022-03-07T06:00:31.939511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建 /kaggle/working/output/AutoEncoderGen/lrG0.0001lrD0.0001bs16ep400/train/img/\r\n",
      "创建 /kaggle/working/output/AutoEncoderGen/lrG0.0001lrD0.0001bs16ep400/train/log/\r\n",
      "创建 /kaggle/working/output/AutoEncoderGen/lrG0.0001lrD0.0001bs16ep400/train/model/\r\n",
      " 22% (2249 of 10000) |####               | Elapsed Time: 0:01:53 ETA:   0:06:085e-05\r\n",
      " 44% (4497 of 10000) |########           | Elapsed Time: 0:03:42 ETA:   0:04:212.5e-05\r\n",
      " 67% (6748 of 10000) |############       | Elapsed Time: 0:05:31 ETA:   0:02:371.25e-05\r\n",
      " 89% (8997 of 10000) |#################  | Elapsed Time: 0:07:20 ETA:   0:00:476.25e-06\r\n",
      "100% (10000 of 10000) |##################| Elapsed Time: 0:08:08 Time:  0:08:08\r\n",
      "创建 /kaggle/working/output/AutoEncoderGen/lrG0.0001lrD0.0001bs16ep400/test//test_img\r\n",
      "创建 /kaggle/working/output/AutoEncoderGen/lrG0.0001lrD0.0001bs16ep400/test//test_log\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "创建 /kaggle/working/output/GAN/lrG0.0001lrD0.0001bs16ep400/train/img/\r\n",
      "创建 /kaggle/working/output/GAN/lrG0.0001lrD0.0001bs16ep400/train/log/\r\n",
      "创建 /kaggle/working/output/GAN/lrG0.0001lrD0.0001bs16ep400/train/model/\r\n",
      "  2% (249 of 10000) |                    | Elapsed Time: 0:00:15 ETA:   0:09:175e-05\r\n",
      "  4% (498 of 10000) |                    | Elapsed Time: 0:00:29 ETA:   0:09:022.5e-05\r\n",
      "  7% (749 of 10000) |#                   | Elapsed Time: 0:00:44 ETA:   0:08:531.25e-05\r\n",
      "  9% (999 of 10000) |#                   | Elapsed Time: 0:00:58 ETA:   0:08:346.25e-06\r\n",
      " 12% (1248 of 10000) |##                 | Elapsed Time: 0:01:13 ETA:   0:08:183.125e-06\r\n",
      " 14% (1499 of 10000) |##                 | Elapsed Time: 0:01:27 ETA:   0:08:121.5625e-06\r\n",
      " 17% (1748 of 10000) |###                | Elapsed Time: 0:01:42 ETA:   0:07:517.8125e-07\r\n",
      " 19% (1999 of 10000) |###                | Elapsed Time: 0:01:56 ETA:   0:07:363.90625e-07\r\n",
      " 22% (2248 of 10000) |####               | Elapsed Time: 0:02:11 ETA:   0:07:285e-05\r\n",
      "1.953125e-07\r\n",
      " 24% (2498 of 10000) |####               | Elapsed Time: 0:02:25 ETA:   0:07:219.765625e-08\r\n",
      " 27% (2749 of 10000) |#####              | Elapsed Time: 0:02:40 ETA:   0:06:544.8828125e-08\r\n",
      " 29% (2998 of 10000) |#####              | Elapsed Time: 0:02:54 ETA:   0:06:532.44140625e-08\r\n",
      " 32% (3249 of 10000) |######             | Elapsed Time: 0:03:09 ETA:   0:06:261.220703125e-08\r\n",
      " 34% (3498 of 10000) |######             | Elapsed Time: 0:03:23 ETA:   0:06:116.103515625e-09\r\n",
      " 37% (3749 of 10000) |#######            | Elapsed Time: 0:03:38 ETA:   0:06:003.0517578125e-09\r\n",
      " 39% (3999 of 10000) |#######            | Elapsed Time: 0:03:53 ETA:   0:05:431.52587890625e-09\r\n",
      " 42% (4248 of 10000) |########           | Elapsed Time: 0:04:07 ETA:   0:05:277.62939453125e-10\r\n",
      " 44% (4499 of 10000) |########           | Elapsed Time: 0:04:22 ETA:   0:05:142.5e-05\r\n",
      "3.814697265625e-10\r\n",
      " 47% (4748 of 10000) |#########          | Elapsed Time: 0:04:36 ETA:   0:05:101.9073486328125e-10\r\n",
      " 49% (4999 of 10000) |#########          | Elapsed Time: 0:04:51 ETA:   0:04:479.5367431640625e-11\r\n",
      " 52% (5248 of 10000) |#########          | Elapsed Time: 0:05:05 ETA:   0:04:404.76837158203125e-11\r\n",
      " 54% (5498 of 10000) |##########         | Elapsed Time: 0:05:20 ETA:   0:04:172.384185791015625e-11\r\n",
      " 57% (5749 of 10000) |##########         | Elapsed Time: 0:05:34 ETA:   0:04:031.1920928955078126e-11\r\n",
      " 59% (5998 of 10000) |###########        | Elapsed Time: 0:05:49 ETA:   0:03:495.960464477539063e-12\r\n",
      " 62% (6249 of 10000) |###########        | Elapsed Time: 0:06:03 ETA:   0:03:352.9802322387695314e-12\r\n",
      " 64% (6498 of 10000) |############       | Elapsed Time: 0:06:18 ETA:   0:03:281.4901161193847657e-12\r\n",
      " 67% (6749 of 10000) |############       | Elapsed Time: 0:06:33 ETA:   0:03:051.25e-05\r\n",
      "7.450580596923828e-13\r\n",
      " 69% (6999 of 10000) |#############      | Elapsed Time: 0:06:47 ETA:   0:02:533.725290298461914e-13\r\n",
      " 72% (7248 of 10000) |#############      | Elapsed Time: 0:07:02 ETA:   0:02:371.862645149230957e-13\r\n",
      " 74% (7499 of 10000) |##############     | Elapsed Time: 0:07:16 ETA:   0:02:229.313225746154786e-14\r\n",
      " 77% (7748 of 10000) |##############     | Elapsed Time: 0:07:31 ETA:   0:02:094.656612873077393e-14\r\n",
      " 79% (7999 of 10000) |###############    | Elapsed Time: 0:07:45 ETA:   0:01:542.3283064365386964e-14\r\n",
      " 82% (8248 of 10000) |###############    | Elapsed Time: 0:08:00 ETA:   0:01:441.1641532182693482e-14\r\n",
      " 84% (8498 of 10000) |################   | Elapsed Time: 0:08:14 ETA:   0:01:275.820766091346741e-15\r\n",
      " 87% (8749 of 10000) |################   | Elapsed Time: 0:08:29 ETA:   0:01:112.9103830456733705e-15\r\n",
      " 89% (8998 of 10000) |#################  | Elapsed Time: 0:08:44 ETA:   0:00:576.25e-06\r\n",
      "1.4551915228366853e-15\r\n",
      " 92% (9249 of 10000) |#################  | Elapsed Time: 0:08:58 ETA:   0:00:447.275957614183426e-16\r\n",
      " 94% (9498 of 10000) |################## | Elapsed Time: 0:09:13 ETA:   0:00:283.637978807091713e-16\r\n",
      " 97% (9749 of 10000) |################## | Elapsed Time: 0:09:27 ETA:   0:00:141.8189894035458566e-16\r\n",
      "100% (10000 of 10000) |##################| Elapsed Time: 0:09:42 Time:  0:09:42\r\n",
      "创建 /kaggle/working/output/GAN/lrG0.0001lrD0.0001bs16ep400/test//test_img\r\n",
      "创建 /kaggle/working/output/GAN/lrG0.0001lrD0.0001bs16ep400/test//test_log\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "创建 /kaggle/working/output/pic2pic/lrG0.0001lrD0.0001bs16ep400/train/img/\r\n",
      "创建 /kaggle/working/output/pic2pic/lrG0.0001lrD0.0001bs16ep400/train/log/\r\n",
      "创建 /kaggle/working/output/pic2pic/lrG0.0001lrD0.0001bs16ep400/train/model/\r\n",
      "  2% (249 of 10000) |                    | Elapsed Time: 0:00:15 ETA:   0:09:165e-05\r\n",
      "  4% (498 of 10000) |                    | Elapsed Time: 0:00:30 ETA:   0:09:142.5e-05\r\n",
      "  7% (749 of 10000) |#                   | Elapsed Time: 0:00:44 ETA:   0:08:511.25e-05\r\n",
      "  9% (999 of 10000) |#                   | Elapsed Time: 0:00:59 ETA:   0:08:436.25e-06\r\n",
      " 12% (1248 of 10000) |##                 | Elapsed Time: 0:01:13 ETA:   0:08:393.125e-06\r\n",
      " 14% (1499 of 10000) |##                 | Elapsed Time: 0:01:28 ETA:   0:08:101.5625e-06\r\n",
      " 17% (1748 of 10000) |###                | Elapsed Time: 0:01:42 ETA:   0:07:517.8125e-07\r\n",
      " 19% (1999 of 10000) |###                | Elapsed Time: 0:01:57 ETA:   0:07:423.90625e-07\r\n",
      " 22% (2248 of 10000) |####               | Elapsed Time: 0:02:12 ETA:   0:07:245e-05\r\n",
      "1.953125e-07\r\n",
      " 24% (2498 of 10000) |####               | Elapsed Time: 0:02:26 ETA:   0:07:109.765625e-08\r\n",
      " 27% (2749 of 10000) |#####              | Elapsed Time: 0:02:41 ETA:   0:07:394.8828125e-08\r\n",
      " 29% (2998 of 10000) |#####              | Elapsed Time: 0:02:56 ETA:   0:06:402.44140625e-08\r\n",
      " 32% (3249 of 10000) |######             | Elapsed Time: 0:03:10 ETA:   0:06:261.220703125e-08\r\n",
      " 34% (3498 of 10000) |######             | Elapsed Time: 0:03:25 ETA:   0:06:276.103515625e-09\r\n",
      " 37% (3749 of 10000) |#######            | Elapsed Time: 0:03:40 ETA:   0:05:593.0517578125e-09\r\n",
      " 39% (3999 of 10000) |#######            | Elapsed Time: 0:03:55 ETA:   0:05:571.52587890625e-09\r\n",
      " 42% (4248 of 10000) |########           | Elapsed Time: 0:04:09 ETA:   0:05:327.62939453125e-10\r\n",
      " 44% (4499 of 10000) |########           | Elapsed Time: 0:04:23 ETA:   0:05:172.5e-05\r\n",
      "3.814697265625e-10\r\n",
      " 47% (4748 of 10000) |#########          | Elapsed Time: 0:04:38 ETA:   0:05:001.9073486328125e-10\r\n",
      " 49% (4999 of 10000) |#########          | Elapsed Time: 0:04:53 ETA:   0:04:499.5367431640625e-11\r\n",
      " 52% (5248 of 10000) |#########          | Elapsed Time: 0:05:08 ETA:   0:04:414.76837158203125e-11\r\n",
      " 54% (5498 of 10000) |##########         | Elapsed Time: 0:05:23 ETA:   0:04:172.384185791015625e-11\r\n",
      " 57% (5749 of 10000) |##########         | Elapsed Time: 0:05:37 ETA:   0:04:111.1920928955078126e-11\r\n",
      " 59% (5998 of 10000) |###########        | Elapsed Time: 0:05:52 ETA:   0:03:485.960464477539063e-12\r\n",
      " 62% (6249 of 10000) |###########        | Elapsed Time: 0:06:06 ETA:   0:03:352.9802322387695314e-12\r\n",
      " 64% (6498 of 10000) |############       | Elapsed Time: 0:06:21 ETA:   0:03:261.4901161193847657e-12\r\n",
      " 67% (6749 of 10000) |############       | Elapsed Time: 0:06:36 ETA:   0:03:061.25e-05\r\n",
      "7.450580596923828e-13\r\n",
      " 69% (6999 of 10000) |#############      | Elapsed Time: 0:06:50 ETA:   0:02:523.725290298461914e-13\r\n",
      " 72% (7248 of 10000) |#############      | Elapsed Time: 0:07:05 ETA:   0:02:391.862645149230957e-13\r\n",
      " 74% (7499 of 10000) |##############     | Elapsed Time: 0:07:20 ETA:   0:02:239.313225746154786e-14\r\n",
      " 77% (7748 of 10000) |##############     | Elapsed Time: 0:07:34 ETA:   0:02:114.656612873077393e-14\r\n",
      " 79% (7999 of 10000) |###############    | Elapsed Time: 0:07:49 ETA:   0:01:582.3283064365386964e-14\r\n",
      " 82% (8248 of 10000) |###############    | Elapsed Time: 0:08:03 ETA:   0:01:401.1641532182693482e-14\r\n",
      " 84% (8498 of 10000) |################   | Elapsed Time: 0:08:18 ETA:   0:01:255.820766091346741e-15\r\n",
      " 87% (8749 of 10000) |################   | Elapsed Time: 0:08:33 ETA:   0:01:122.9103830456733705e-15\r\n",
      " 89% (8998 of 10000) |#################  | Elapsed Time: 0:08:48 ETA:   0:00:596.25e-06\r\n",
      "1.4551915228366853e-15\r\n",
      " 92% (9249 of 10000) |#################  | Elapsed Time: 0:09:02 ETA:   0:00:437.275957614183426e-16\r\n",
      " 94% (9498 of 10000) |################## | Elapsed Time: 0:09:17 ETA:   0:00:283.637978807091713e-16\r\n",
      " 97% (9749 of 10000) |################## | Elapsed Time: 0:09:32 ETA:   0:00:141.8189894035458566e-16\r\n",
      "100% (10000 of 10000) |##################| Elapsed Time: 0:09:46 Time:  0:09:46\r\n",
      "创建 /kaggle/working/output/pic2pic/lrG0.0001lrD0.0001bs16ep400/test//test_img\r\n",
      "创建 /kaggle/working/output/pic2pic/lrG0.0001lrD0.0001bs16ep400/test//test_log\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n",
      "0\r\n",
      "1\r\n",
      "2\r\n",
      "3\r\n"
     ]
    }
   ],
   "source": [
    "!python command.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1737.279159,
   "end_time": "2022-03-07T06:28:59.470714",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-07T06:00:02.191555",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
