{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install progressbar2\n!pip install fitlog\n!fitlog init\n%mkdir utils/",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:07.585563Z",
     "iopub.execute_input": "2022-03-07T03:20:07.586319Z",
     "iopub.status.idle": "2022-03-07T03:20:24.097556Z",
     "shell.execute_reply.started": "2022-03-07T03:20:07.586267Z",
     "shell.execute_reply": "2022-03-07T03:20:24.096709Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile command.py\nimport os\n\nep = 100\nlrG = 0.0001\nbs = 16\n\nos.system('python my_train.py --model_name AutoEncoderGen --ep %d --lrG %f --bs %d' % (ep, lrG, bs))\nos.system('python my_train.py --model_name GAN --ep %d --lrG %f --bs %d' % (ep, lrG, bs))\nos.system('python my_train.py --model_name pic2pic --ep %d --lrG %f --bs %d' % (ep, lrG, bs))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.100129Z",
     "iopub.execute_input": "2022-03-07T03:20:24.100906Z",
     "iopub.status.idle": "2022-03-07T03:20:24.107742Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.100867Z",
     "shell.execute_reply": "2022-03-07T03:20:24.107055Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile my_train.py\nimport argparse\nimport fitlog\nimport io\n\nfrom torchvision.utils import save_image\n\nfrom torch.utils.data import DataLoader\nfrom dataset import *\nimport utils.file_manager as fm\n\nfrom utils.model_controller import *\n\ntry:\n    import ipdb\nexcept:\n    import pdb as ipdb\n\nimport time\nimport progressbar\n\npro = progressbar.ProgressBar()\n\nparser = argparse.ArgumentParser()  # 创建解析器对象 可以添加参数\nparser.add_argument('--model_name', type=str, default='test', help='模型名称')\nparser.add_argument('--lrG', type=float, default=1e-4, help='adam: learning rate')\nparser.add_argument('--lrD', type=float, default=1e-4, help='adam: learning rate')\nparser.add_argument('--bs', type=int, default=8, help='size of the batches')\nparser.add_argument('--ep', type=int, default=200, help='number of epochs of training')\nparser.add_argument('--lrG_d', type=int, default=90, help='G lr down')\nparser.add_argument('--lrD_d', type=int, default=10, help='D lr down')\nparser.add_argument('--weight_pic', type=float, default=10, help='计算生成器loss时,pic_loss的比例')\nparser.add_argument('--epoch', type=int, default=0, help='epoch to start training from')\nparser.add_argument('--dataset_name', type=str, default='test', help='name of the dataset')\n\nparser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')\nparser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')\nparser.add_argument('--decay_epoch', type=int, default=100, help='epoch from which to start lr decay')\nparser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\nparser.add_argument('--img_height', type=int, default=64, help='size of image height')\nparser.add_argument('--img_width', type=int, default=64, help='size of image width')\nparser.add_argument('--channels', type=int, default=3, help='number of image channels')\nparser.add_argument('--sample_interval', type=int, default=500,\n                    help='interval between sampling of images from generators')\nparser.add_argument('--checkpoint_interval', type=int, default=20, help='interval between model checkpoints')\n\nopt = parser.parse_args()\nif_fitlog = True\n\ndata_path = '../input/mldesign03/fontdata'\ncuda = True if torch.cuda.is_available() else False\ntest = True\n\ntrain_opt = fm.Train_opt(opt)\n# Initialize generator and discriminator\nmodel_name = train_opt['model_name']\n\nif if_fitlog:\n    fitlog.set_log_dir('logs/')  # 设置log文件夹为'logs/', fitlog在每次运行的时候会默认以时间戳的方式在里面生成新的log\n    fitlog.add_hyper(train_opt.get_fitlog_hyper())\n\ntransforms_ = [transforms.ToTensor(),\n               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n\n# 修改成本地存放数据集地址\ndataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_),\n                        batch_size=opt.bs, shuffle=True, num_workers=0)\ntrain_opt['dataloader_length'] = len(dataloader)\n\nval_dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_, mode='train'),\n                            batch_size=20, shuffle=False, num_workers=0)\n\n# Tensor type\nTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n\n\nmodel = model_selector(train_opt.opt)\n# 为网络参数赋初值\nmodel.apply(weights_init_normal)\nif cuda:\n    model.cuda()\n\n\ndef sample_images(batches_done):\n    \"\"\"Saves a generated sample from the validation set\"\"\"\n    imgs = next(iter(val_dataloader))\n    real_A = imgs['B'].type(Tensor)\n    real_B = imgs['A'].type(Tensor)\n    fake_B = model.generator(real_A)\n    img_sample = torch.cat((real_A.data, fake_B.data, real_B.data), -2)\n    # ipdb.set_trace()\n    save_image(img_sample, train_opt.get_img_root() + '%s.png' % batches_done, nrow=5, normalize=True)\n\n\n# ----------\n#  Training\n# ----------\nmodel.train()\n\nmin_tloss = 500\ntloss_res = {}\n\nbs_count = len(dataloader)\npro.start(train_opt['ep'] * bs_count)\n\nfor epoch in range(opt.epoch, opt.ep):\n\n    for i, batch in enumerate(dataloader):\n\n        # Model inputs\n        source = batch['B'].type(Tensor)\n        target = batch['A'].type(Tensor)\n        loss_dic = model.step(source, target)\n\n        batches_done = epoch * len(dataloader) + i\n        # If at sample interval save image\n        if int(batches_done*train_opt['bs']/8) % int(train_opt['sample_interval']) == 0:\n            sample_images(batches_done)\n        # 打印进度条\n        pro.update(i + epoch * bs_count)\n\n    avg_loss = 0\n    tloss_res[epoch] = avg_loss\n\n    if if_fitlog:\n        fitlog.add_metric(loss_dic, epoch)\n        fitlog.add_best_metric(loss_dic)\n\n    # 每50轮保存模型参数\n    if epoch > 0 and (epoch + 1) % 50 == 0:\n        torch.save(model.state_dict(), '%s/%s_%d.pth' % (train_opt.get_model_root(), model_name, epoch))\n        # torch.save(discriminator.state_dict(),\n        #            train_opt.get_model_root() + '/discriminator_%d.pth' % epoch)\n        # torch.save(model.state_dict())\n    # 保存loss最小时的模型参数\n    # if tloss_res[epoch] < min_tloss:\n    #     min_tloss = tloss_res[epoch]\n    #     tloss_res['min'] = tloss_res[epoch]\n    #     tloss_res['minepoch'] = epoch\n    #     torch.save(model.state_dict(), '%s/%s_min.pth' % (train_opt.get_model_root(), model_name))\n\nwith io.open(train_opt.get_log_root() + 'list_loss.txt', 'a', encoding='utf-8') as file:\n    file.write('tloss_res: {} \\n'.format(tloss_res))\npro.finish()\nif test:\n    os.system('python test.py --model_dir \\\"%s\\\" --model_name %s' % (train_opt.get_model_root(), model_name))",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.109331Z",
     "iopub.execute_input": "2022-03-07T03:20:24.109922Z",
     "iopub.status.idle": "2022-03-07T03:20:24.122122Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.109886Z",
     "shell.execute_reply": "2022-03-07T03:20:24.121390Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile test.py\nimport argparse\nfrom torchvision.utils import save_image\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\nfrom utils.file_manager import *\nfrom dataset import *\nimport torch\n\nfrom utils.model_controller import model_selector\n\ntry:\n    import ipdb\nexcept:\n    import pdb as ipdb\n\nparser = argparse.ArgumentParser()  # 创建解析器对象 可以添加参数\n# 为了找到训练模型参数地址，要与train.py中model_name参数一致\nparser.add_argument('--model_dir', type=str, default=\"test\", help='模型文件夹')\nparser.add_argument('--model_name', type=str, default=\"test\", help='模型名')\nopt = parser.parse_args()\nmy_opt = Test_opt(opt)\ncuda = True if torch.cuda.is_available() else False\ndata_path = '../input/mldesign03/fontdata'\nmodel = model_selector(my_opt.opt['model_name'])\n\nif cuda:\n    model.cuda()\n\ntransforms_ = [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n\n# ImageDataset第一个参数改成个人数据集存放地址\nval_dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_, mode='test'),\n                            batch_size=20, shuffle=False, num_workers=0)\n\nTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n\nmodel_dict = my_opt.get_model_root()\nfilename = os.listdir(model_dict)\n\nfor j in range(len(filename)):\n    if os.path.splitext(filename[j])[1] == '.pth':\n        model.load_state_dict(torch.load('%s/%s' % (model_dict, filename[j])))\n        model.eval()\n        for i, batch in enumerate(val_dataloader):\n            print(i)\n            real_A = Variable(batch['B'].type(Tensor))\n            real_B = Variable(batch['A'].type(Tensor))\n            fake_B = model.generator(real_A)\n            # 图片存放处\n            save_image(fake_B, my_opt.get_img_root()+'/%s.png' % ('img'+str(i) + '_' + filename[j].split('.')[0]), nrow=10,\n                       normalize=True)\n            save_image(real_B, my_opt.get_img_root()+'/%s.png' % str(i), nrow=10, normalize=True)\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.123855Z",
     "iopub.execute_input": "2022-03-07T03:20:24.124423Z",
     "iopub.status.idle": "2022-03-07T03:20:24.137021Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.124389Z",
     "shell.execute_reply": "2022-03-07T03:20:24.136302Z"
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile myModel.py\nfrom torch import nn\nfrom utils.my_optimizer import *\n\ngenerator_loss_fun = torch.nn.L1Loss()\ndiscriminator_loss_fun = torch.nn.MSELoss()\n\n\n# ===================================\n#              网络单元\n# ===================================\nclass Encoder(nn.Module):\n    def __init__(self, in_size, out_size, normalize=True, dropout=0.0, ks=4):\n\n        super(Encoder, self).__init__()\n        layers = [nn.Conv2d(in_size, out_size, kernel_size=ks, stride=2, padding=1, bias=False)]\n        if normalize:\n            layers.append(nn.InstanceNorm2d(out_size))\n        layers.append(nn.LeakyReLU(0.2))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass Decoder(nn.Module):\n    def __init__(self, in_size, out_size, dropout=0.0, normalize=True):\n        super(Decoder, self).__init__()\n        layers = [nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False)]\n        if normalize:\n            layers.append(nn.InstanceNorm2d(out_size))\n        layers.append(nn.ReLU(inplace=True))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nclass UNetDown(nn.Module):\n    def __init__(self, in_size, out_size, normalize=True, dropout=0.0, ks=4):\n\n        super(UNetDown, self).__init__()\n        layers = [nn.Conv2d(in_size, out_size, kernel_size=ks, stride=2, padding=1, bias=False)]\n        if normalize:\n            layers.append(nn.InstanceNorm2d(out_size))\n        layers.append(nn.LeakyReLU(0.2))\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\n\nclass UNetUp(nn.Module):\n    def __init__(self, in_size, out_size, dropout=0.0, if_crop=True):\n        super(UNetUp, self).__init__()\n        layers = [nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1, bias=False),\n                  nn.InstanceNorm2d(out_size),\n                  nn.ReLU(inplace=True)]\n        if dropout:\n            layers.append(nn.Dropout(dropout))\n\n        self.model = nn.Sequential(*layers)\n        self.if_crop = if_crop\n\n    def forward(self, x, skip_input):\n        # ipdb.set_trace()\n        x = self.model(x)\n        if self.if_crop > 0:\n            x = torch.cat((x, skip_input), 1)\n        else:\n            x = torch.cat((x, x), 1)\n        return x\n\n\n# ===================================\n#              子模型\n# ===================================\nclass GeneratorUNet(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, if_crop=True, loss_fun=generator_loss_fun):\n        super(GeneratorUNet, self).__init__()\n        self.down1 = UNetDown(in_channels, 64, normalize=False)\n        self.down2 = UNetDown(64, 128)\n        self.down3 = UNetDown(128, 256)\n        self.down4 = UNetDown(256, 512, dropout=0.5)\n        self.down5 = UNetDown(512, 512, dropout=0.5)\n        self.down6 = UNetDown(512, 512, dropout=0.5, normalize=False)  # 不需要正规化了\n\n        self.up1 = UNetUp(512, 512, dropout=0.5, if_crop=if_crop)\n        self.up2 = UNetUp(1024, 512, dropout=0.5, if_crop=if_crop)\n        self.up3 = UNetUp(1024, 256, if_crop=if_crop)\n        self.up4 = UNetUp(512, 128, if_crop=if_crop)\n        self.up5 = UNetUp(256, 64, if_crop=if_crop)\n\n        self.final = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(128, out_channels, 4, padding=1),\n            nn.Tanh()\n        )\n        self.loss_fun = loss_fun\n\n    def forward(self, x):\n        # U-Net generator with skip connections from encoder to decoder\n        d1 = self.down1(x)  # x:[1, 3, 64, 64]  d1:[1, 64, 32, 32]\n        d2 = self.down2(d1)  # d2:[1,128,16,16]\n        d3 = self.down3(d2)  # d3:[1,256,8,8]\n        d4 = self.down4(d3)  # d4:[1,512,4,4]\n        d5 = self.down5(d4)  # d5:[1,512,2,2]\n        d6 = self.down6(d5)  # d6:[1,512,1,1]\n\n        u1 = self.up1(d6, d5)  # u1:[1,1024,2,2]\n        u2 = self.up2(u1, d4)  # u2:[1,1024,4,4]\n        u3 = self.up3(u2, d3)  # u3:[1,1024,8,8]\n        u4 = self.up4(u3, d2)  # u4:[1,1024,16,16]\n        u5 = self.up5(u4, d1)  # u5:[1,512,32,32]\n        return self.final(u5)\n\n    def loss(self, generate, target):\n        return self.loss_fun(generate, target)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, loss_fun=discriminator_loss_fun):\n        super(Discriminator, self).__init__()\n\n        def discriminator_block(in_filters, out_filters, normalization=True):\n            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n            if normalization:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *discriminator_block(in_channels * 2, 64, normalization=False),\n            *discriminator_block(64, 128),\n            *discriminator_block(128, 256),\n            *discriminator_block(256, 512),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n        )\n        self.loss_fun = loss_fun\n\n    def forward(self, img_A, img_B):\n        # Concatenate image and condition image\n        # by channels to produce input\n        img_input = torch.cat((img_A, img_B), 1)\n        return self.model(img_input)\n\n    def loss(self, pred, real):\n        return self.loss_fun(pred, real)\n\n\nclass AutoEncoder(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, loss_fun=generator_loss_fun):\n        super(AutoEncoder, self).__init__()\n        self.down1 = Encoder(in_channels, 64, normalize=False)\n        self.down2 = Encoder(64, 128)\n        self.down3 = Encoder(128, 256)\n        self.down4 = Encoder(256, 512, dropout=0.5)\n        self.down5 = Encoder(512, 512, dropout=0.5)\n        self.down6 = Encoder(512, 512, dropout=0.5, normalize=False)  # 不需要正规化了\n\n        self.up1 = Decoder(512, 1024, dropout=0.5)\n        self.up2 = Decoder(1024, 1024, dropout=0.5)\n        self.up3 = Decoder(1024, 512)\n        self.up4 = Decoder(512, 256)\n        self.up5 = Decoder(256, 128)\n\n        self.final = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(128, out_channels, 4, padding=1),\n            nn.Tanh()\n        )\n        self.loss_fun = loss_fun\n\n    def forward(self, x):\n        # 上采样\n        d1 = self.down1(x)  # x:[1, 3, 64, 64]  d1:[1, 64, 32, 32]\n        d2 = self.down2(d1)  # d2:[1,128,16,16]\n        d3 = self.down3(d2)  # d3:[1,256,8,8]\n        d4 = self.down4(d3)  # d4:[1,512,4,4]\n        d5 = self.down5(d4)  # d5:[1,512,2,2]\n        d6 = self.down6(d5)  # d6:[1,512,1,1]\n        # 下采样\n        u1 = self.up1(d6)  # u1:[1,1024,2,2]\n        u2 = self.up2(u1)  # u2:[1,1024,4,2]\n        u3 = self.up3(u2)  # u3:[1,1024,8,2]\n        u4 = self.up4(u3)  # u4:[1,1024,16,16]\n        u5 = self.up5(u4)  # u5:[1,512,32,32]\n        x = self.final(u5)\n        return x\n\n    def loss(self, x, y):\n        return self.loss_fun(x, y)\n\n\n# ===================================\n#              顶级模型\n# ===================================\nclass GAN(nn.Module):\n    def __init__(self, train_opt=None, generator=GeneratorUNet(), discriminator=Discriminator()):\n        super(GAN, self).__init__()\n        self.generator = generator\n        self.discriminator = discriminator\n        if isinstance(train_opt, dict):\n            self.optimizer_G = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrG'],\n                                              betas=(train_opt['b1'], train_opt['b2']),\n                                              freq=train_opt['lrG_d'] * train_opt['dataloader_length'])\n\n            self.optimizer_D = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrD'],\n                                              betas=(train_opt['b1'], train_opt['b2']),\n                                              freq=train_opt['lrD_d'] * train_opt['dataloader_length'])\n            self.train_opt = train_opt\n\n    def forward(self, source, target):\n        generate = self.generator(source)\n        source_generate = self.discriminator(generate, source)\n        source_target = self.discriminator(target, source)\n        source_generate2 = self.discriminator(generate.detach(), source)\n        return generate, source_generate, source_target, source_generate2\n\n    def loss(self, generate, target, source_generate, source_target, source_generate2):\n        invalid = source_target.clone().detach() * 0\n        valid = invalid + 1\n        # 计算生成模型误差\n        loss_pixel = self.generator.loss(generate, target)\n        loss_sVg = self.discriminator.loss(source_generate, valid)\n        loss_G = loss_sVg + self.train_opt['weight_pic'] * loss_pixel\n        # 分辨源图像和目标图像\n        loss_real = self.discriminator.loss(source_target, valid)\n        # 分辨源图像和生成图像\n        loss_fake = self.discriminator.loss(source_generate2, invalid)\n        # Total loss\n        loss_D = 0.5 * (loss_real + loss_fake)\n        return loss_G, loss_D, loss_sVg, loss_pixel\n\n    def step(self, source, target):\n        generate, source_generate, source_target, source_generate2 = self(source, target)\n        loss_G, loss_D, loss_sVg, loss_pixel = self.loss(generate, target, source_generate,\n                                                         source_target, source_generate2)\n        self.optimizer_G.zero_grad()\n        loss_G.backward()\n        self.optimizer_G.step()\n\n        self.optimizer_D.zero_grad()\n        loss_D.backward()\n        self.optimizer_D.step()\n        loss_dic = {'loss_G': loss_G.item(), 'loss_D': loss_D.item(), 'loss_pixel': loss_pixel.item(),\n                    'loss_sVg': loss_sVg.item()}\n        return loss_dic\n\n\n# 基于AutoEncoder的图片生成器\nclass AutoEncoderGen(nn.Module):\n    def __init__(self, train_opt=None, generator=AutoEncoder()):\n        super(AutoEncoderGen, self).__init__()\n        self.generator = generator\n        if isinstance(train_opt, dict):\n            self.optimizer_G = Adam_Optimizer(parameters=self.generator.parameters(), lr=train_opt['lrG'],\n                                              betas=(train_opt['b1'], train_opt['b2']),\n                                              freq=train_opt['lrG_d'] * train_opt['dataloader_length'])\n\n    def loss(self, x, y):\n        return self.generator.loss_fun(x, y)\n\n    def forward(self, x):\n        return self.generator(x)\n\n    # 只有作为顶级模型时该方法有效合法\n    def step(self, x, y):\n        generate = self(x)\n        loss_pixel = self.loss(y, generate) * 10\n        self.optimizer_G.zero_grad()\n        loss_pixel.backward()\n        self.optimizer_G.step()\n        loss_dic = {'loss_pixel': loss_pixel.item()}\n        return loss_dic",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.140881Z",
     "iopub.execute_input": "2022-03-07T03:20:24.141297Z",
     "iopub.status.idle": "2022-03-07T03:20:24.156546Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.141261Z",
     "shell.execute_reply": "2022-03-07T03:20:24.155677Z"
    },
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "trusted": true
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile dataset.py\nimport glob\nimport random\nimport os\nimport numpy as np\nimport torch\n\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n# from sklearn.cross_validation import train_test_split\ntry:\n    import ipdb\nexcept:\n    import pdb as ipdb\n\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, mode='train'):\n        self.transform = transforms.Compose(transforms_)\n        # ipdb.set_trace()\n        rootPath = root + '/{}'.format(mode)\n        filename = os.listdir(rootPath)\n        path = rootPath + '/' + filename[0]\n\n        self.imgs = np.load(path)\n\n    def __getitem__(self, index):\n        img_A_a = self.imgs[index][:, :64, :]\n        img_B_b = self.imgs[index][:, 64:, :]\n\n        img_A = self.transform(img_A_a.astype(np.uint8))  # 京黑\n        img_B = self.transform(img_B_b.astype(np.uint8))  # 黑体\n\n        return {'A': img_A, 'B': img_B}\n\n    def __len__(self):\n        return len(self.imgs)\n\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.158011Z",
     "iopub.execute_input": "2022-03-07T03:20:24.158974Z",
     "iopub.status.idle": "2022-03-07T03:20:24.169975Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.158937Z",
     "shell.execute_reply": "2022-03-07T03:20:24.169271Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile utils/file_manager.py\n'''\n由opt决定的文件树\n'''\nimport os\nimport tkinter as tk\nfrom tkinter import filedialog\nfrom utils.model_controller import valid_model_name\n\n\nclass Train_opt:\n    def __init__(self, opt, root=os.getcwd() + '/output'):\n        super(Train_opt, self).__init__()\n        # 将opt转为字典类型\n        if not isinstance(opt, dict):\n            self.opt = vars(opt)\n        else:\n            self.opt = opt\n        self.root = root\n        self.mk_use_dirs()\n\n    def __getitem__(self, item):\n        return self.opt.__getitem__(item)\n\n    def __setitem__(self, key, value):\n        self.opt.__setitem__(key, value)\n\n    # 获得本次输出的根目录\n    def get_root(self):\n        # 格式：模型/G学习率_D学习率_批大小_epoch\n        opt = self.opt\n        dir_name = ''\n        k_hyper = self.get_key_hyper()\n        for k, v in k_hyper.items():\n            dir_name += str(k) + str(v)\n        root = '%s/%s/%s/train' % (self.root, opt['model_name'], dir_name)\n        return root\n\n    # 获得log存放路径\n    def get_log_root(self):\n        return self.get_root() + '/log/'\n\n    # 获得model存放路径\n    def get_model_root(self):\n        return self.get_root() + '/model/'\n\n    # 获得img存放路径\n    def get_img_root(self):\n        return self.get_root() + '/img/'\n\n    # 返回用于命名文件夹的超参\n    def get_key_hyper(self):\n        k = ['lrG', 'lrD', 'bs', 'ep']\n        v = {key: value for key, value in self.opt.items() if key in k}\n        return v\n\n    def get_fitlog_hyper(self):\n        k = ['lrG', 'lrD', 'bs', 'ep', 'model_name']\n        v = {key: value for key, value in self.opt.items() if key in k}\n        return v\n\n    # 命名可能需要的文件夹\n    def mk_use_dirs(self):\n        print('创建 ' + self.get_img_root())\n        print('创建 ' + self.get_log_root())\n        print('创建 ' + self.get_model_root())\n        os.makedirs(self.get_log_root(), exist_ok=True)\n        os.makedirs(self.get_img_root(), exist_ok=True)\n        os.makedirs(self.get_model_root(), exist_ok=True)\n\n\nclass Test_opt:\n    def __init__(self, opt):\n        super(Test_opt, self).__init__()\n        # 将opt转为字典类型\n        if not isinstance(opt, dict):\n            self.opt = vars(opt)\n        else:\n            self.opt = opt\n\n        try:\n            model_dir = self.opt['model_dir']\n            had_set = model_dir.split('/')[-4] not in valid_model_name\n        except (KeyError, IndexError):\n            print(\"未指定合法目录,请手动选择待测试模型位置\")\n            had_set = False\n\n        while self.opt['model_name'] not in valid_model_name or not had_set:\n            root = tk.Tk()\n            root.withdraw()\n            model_dir = filedialog.askdirectory()\n            self.opt['model_name'] = model_dir.split('/')[-4]\n            had_set = True\n\n        self.mode_dir = model_dir\n        self.test_out = model_dir.replace('train', 'test', 1)\n        self.test_out = self.test_out.replace('/model', '')\n        self.mk_use_dirs()\n\n    def __getitem__(self, item):\n        return self.opt.__getitem__(item)\n\n    def __setitem__(self, key, value):\n        self.opt.__setitem__(key, value)\n\n    def get_root(self):\n        return self.test_out\n\n    def get_img_root(self):\n        return self.get_root() + '/test_img'\n\n    def get_log_root(self):\n        return self.get_root() + '/test_log'\n\n    def get_model_root(self):\n        return self.mode_dir\n\n    def mk_use_dirs(self):\n        print('创建 '+self.get_img_root())\n        print('创建 '+self.get_log_root())\n        os.makedirs(self.get_log_root(), exist_ok=True)\n        os.makedirs(self.get_img_root(), exist_ok=True)\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.171433Z",
     "iopub.execute_input": "2022-03-07T03:20:24.171846Z",
     "iopub.status.idle": "2022-03-07T03:20:24.183399Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.171810Z",
     "shell.execute_reply": "2022-03-07T03:20:24.182737Z"
    },
    "trusted": true
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile utils/model_controller.py\nimport myModel\nfrom myModel import *\n\nvalid_model_name = ['GAN', 'AutoEncoderGen', 'pic2pic']\n\n\n# 为网络参数赋正态分布的初值\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm2d') != -1:\n        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n\n\n# 根据opt选取模型\ndef model_selector(opt):\n    if isinstance(opt, dict):\n        model_name = opt['model_name']\n    else:\n        model_name = opt\n\n    generator_list = {'UNet': GeneratorUNet(), 'GAN': GeneratorUNet(if_crop=False), 'AutoEncoder': AutoEncoder()}\n    discriminator_list = {'Discriminator': Discriminator()}\n\n    while model_name not in valid_model_name:\n        print('未输入正确模型名 请输入正确模型名\\n')\n        print(valid_model_name)\n        model_name = input()\n\n    if model_name == 'AutoEncoderGen':\n        model = AutoEncoderGen(train_opt=opt, generator=generator_list['AutoEncoder'])\n\n    if model_name == 'GAN':\n        generator = generator_list['GAN']\n        discriminator = discriminator_list['Discriminator']\n        model = GAN(train_opt=opt, generator=generator, discriminator=discriminator)\n\n    if model_name == 'pic2pic':\n        generator = generator_list['UNet']\n        discriminator = discriminator_list['Discriminator']\n        model = GAN(train_opt=opt, generator=generator, discriminator=discriminator)\n\n    return model",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.184940Z",
     "iopub.execute_input": "2022-03-07T03:20:24.185465Z",
     "iopub.status.idle": "2022-03-07T03:20:24.196842Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.185371Z",
     "shell.execute_reply": "2022-03-07T03:20:24.196131Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "%%writefile utils/my_optimizer.py\nimport torch\n\n\nclass Adam_Optimizer:\n    # freq表示学习率折半的频率 每更新freq次参数学习率折半 (对于lrd, freq=lrG_d*dataloader_length) 当freq取0时, 不更新\n    def __init__(self, parameters, lr, betas, freq=0):\n        super(Adam_Optimizer, self).__init__()\n        self.optimizer = torch.optim.Adam(parameters, lr=lr, betas=betas)\n        self.freq = freq\n        self.times = 0\n        self.lr = lr\n\n    def step(self):\n        if self.times % self.freq == 0 and self.times > 0:\n            self.lr *= 0.5\n            self.optimizer.param_groups[0]['lr'] = self.lr\n            print(self.lr)\n        self.optimizer.step()\n        self.times += 1\n\n    def zero_grad(self):\n        self.optimizer.zero_grad()\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.198384Z",
     "iopub.execute_input": "2022-03-07T03:20:24.198880Z",
     "iopub.status.idle": "2022-03-07T03:20:24.209142Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.198844Z",
     "shell.execute_reply": "2022-03-07T03:20:24.208401Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!python command.py",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-07T03:20:24.210787Z",
     "iopub.execute_input": "2022-03-07T03:20:24.211312Z",
     "iopub.status.idle": "2022-03-07T03:28:01.999831Z",
     "shell.execute_reply.started": "2022-03-07T03:20:24.211274Z",
     "shell.execute_reply": "2022-03-07T03:28:01.999006Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": []
  }
 ]
}